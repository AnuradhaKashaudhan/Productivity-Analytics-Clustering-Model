{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T09:20:54.855239Z",
     "start_time": "2025-04-08T09:20:50.377838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import catboost as cb\n",
    "import optuna\n",
    "\n",
    "# Suppress warnings for clean output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "print(f\"üöÄ Starting pipeline at {time.ctime()}\")\n",
    "\n",
    "# ======= File paths =======\n",
    "model_path             = \"D:\\Python\\Models\\gpu_lightgbm_model.pkl\"\n",
    "scaler_path            = \"D:\\Python\\Models\\scaler.pkl\"\n",
    "selected_features_path = \"D:\\Python\\Models\\selected_features.pkl\"\n",
    "poly_path              = \"D:\\Python\\Models\\poly.pkl\"\n",
    "feature_defs_path      = \"D:\\Python\\Models\\Feature_defs.pkl\"\n",
    "X_columns_path         = \"D:\\Python\\Models\\X_columns.pkl\"\n",
    "imputer_path           = \"D:\\Python\\Models\\imputer.pkl\"  # Added imputer path\n",
    "output_dir = os.path.dirname(model_path)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(f\"üìÅ Ensured output directory exists: {output_dir}\")\n",
    "\n",
    "# ======= Phase 1: Load Dataset =======\n",
    "data_path     = \"D:\\Python\\Datasets\\Handled_Training_Data.csv\"\n",
    "target_column = 'target'\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(data_path)\n",
    "    print(f\"‚úÖ Dataset loaded! Shape: {data.shape}\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error loading dataset:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# Remove rows with missing target\n",
    "try:\n",
    "    data = data.loc[data[target_column].notna()]\n",
    "    print(\"‚úÖ Removed rows with missing target values.\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error removing missing target rows:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# ======= Phase 2: Train-Test Split =======\n",
    "try:\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "    print(f\"‚úÖ Train-Test split: {X_train.shape} train, {X_test.shape} test\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error during train-test split:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# ======= Phase 3: Encode Categorical Variables =======\n",
    "print(\"üß† Phase 3: Encoding categorical variables...\")\n",
    "try:\n",
    "    cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    if cat_cols:\n",
    "        ohe = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "        X_train_cat = pd.DataFrame(\n",
    "            ohe.fit_transform(X_train[cat_cols]),\n",
    "            columns=ohe.get_feature_names_out(cat_cols),\n",
    "            index=X_train.index\n",
    "        )\n",
    "        X_train = pd.concat([X_train.drop(columns=cat_cols), X_train_cat], axis=1)\n",
    "        joblib.dump((X_train.columns.tolist(), ohe), X_columns_path)\n",
    "        print(f\"‚úÖ Encoded categoricals and saved encoder to {X_columns_path}\")\n",
    "\n",
    "        X_test_cat = pd.DataFrame(\n",
    "            ohe.transform(X_test[cat_cols]),\n",
    "            columns=ohe.get_feature_names_out(cat_cols),\n",
    "            index=X_test.index\n",
    "        )\n",
    "        X_test = pd.concat([X_test.drop(columns=cat_cols), X_test_cat], axis=1)\n",
    "    else:\n",
    "        print(\"‚úÖ No categorical columns to encode.\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error encoding categoricals:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# ======= Phase 4: Remove Outliers =======\n",
    "print(\"üßπ Phase 4: Removing outliers from training data...\")\n",
    "try:\n",
    "    num_cols = X_train.select_dtypes(include=np.number).columns\n",
    "    iso = IsolationForest(random_state=42, contamination=0.1)\n",
    "    mask = iso.fit_predict(X_train[num_cols]) == 1\n",
    "    X_train, y_train = X_train[mask], y_train[mask]\n",
    "    print(f\"‚úÖ Outlier removal done. Training shape now: {X_train.shape}\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error during outlier removal:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# ======= Phase 5: Generate Polynomial Features =======\n",
    "print(\"üõ†Ô∏è Phase 5: Generating polynomial features on training data...\")\n",
    "try:\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    X_train_poly = pd.DataFrame(\n",
    "        poly.fit_transform(X_train),\n",
    "        columns=poly.get_feature_names_out(X_train.columns),\n",
    "        index=X_train.index\n",
    "    )\n",
    "    joblib.dump(poly, poly_path)\n",
    "    print(f\"‚úÖ PolynomialFeatures saved to {poly_path}\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error generating polynomial features:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# ======= Phase 6: Feature Engineering with Featuretools =======\n",
    "print(\"üß† Phase 6: Featuretools engineering on training data...\")\n",
    "try:\n",
    "    Xf = X_train.copy()\n",
    "    Xf['idx'] = Xf.index\n",
    "    es = ft.EntitySet(id=\"train_dataset\")\n",
    "    es.add_dataframe(dataframe_name=\"df\", dataframe=Xf, index=\"idx\")\n",
    "    fm_train, fdefs = ft.dfs(\n",
    "        entityset=es,\n",
    "        target_dataframe_name=\"df\",\n",
    "        max_depth=1,\n",
    "        verbose=False\n",
    "    )\n",
    "    new_feats = [c for c in fm_train.columns if c not in X_train.columns and c != 'idx']\n",
    "    X_train_ft = fm_train[new_feats].reset_index(drop=True)\n",
    "    joblib.dump(fdefs, feature_defs_path)\n",
    "    print(f\"‚úÖ {len(new_feats)} Featuretools features saved to {feature_defs_path}\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error in Featuretools phase:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# ======= Phase 7: Combine Features =======\n",
    "print(\"üîó Phase 7: Combining polynomial + engineered features...\")\n",
    "try:\n",
    "    X_train_poly = X_train_poly.reset_index(drop=True)\n",
    "    X_train_ft   = X_train_ft.reset_index(drop=True)\n",
    "    X_train_final = pd.concat([X_train_poly, X_train_ft], axis=1)\n",
    "    print(f\"‚úÖ Combined training matrix shape: {X_train_final.shape}\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error combining features:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# ======= Phase 8: Impute Missing Values =======\n",
    "print(\"üß© Phase 8: Imputing missing values in training data...\")\n",
    "try:\n",
    "    if X_train_final.isnull().any().any():\n",
    "        imputer = SimpleImputer(strategy=\"mean\")\n",
    "        X_train_final = pd.DataFrame(\n",
    "            imputer.fit_transform(X_train_final),\n",
    "            columns=X_train_final.columns\n",
    "        )\n",
    "        joblib.dump(imputer, imputer_path)  # Save imputer\n",
    "        print(f\"‚úÖ Missing values imputed and saved to {imputer_path}\")\n",
    "    else:\n",
    "        print(\"‚úÖ No missing values detected.\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error during imputation:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# ======= Phase 9: Scale Training Features =======\n",
    "print(\"‚öôÔ∏è Phase 9: Scaling training features...\")\n",
    "try:\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_final)\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(f\"‚úÖ Features scaled and scaler saved to {scaler_path}\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error during scaling:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# ======= Phase 10: Feature Selection =======\n",
    "print(\"üîç Phase 10: Feature selection using CatBoost on training data...\")\n",
    "try:\n",
    "    selector_model = cb.CatBoostRegressor(\n",
    "        verbose=0, task_type=\"GPU\", devices='0', random_state=42\n",
    "    )\n",
    "    selector_model.fit(X_train_scaled, y_train)\n",
    "    selector = SelectFromModel(selector_model, threshold=\"median\", prefit=True)\n",
    "    X_train_selected = selector.transform(X_train_scaled)\n",
    "    selected_features = list(np.array(X_train_final.columns)[selector.get_support()])\n",
    "    joblib.dump(selected_features, selected_features_path)\n",
    "    print(f\"‚úÖ Feature selection completed and saved to {selected_features_path}\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error during feature selection:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# ======= Phase 11: Hyperparameter Tuning with Optuna =======\n",
    "print(\"üéØ Phase 11: Hyperparameter tuning with Optuna...\")\n",
    "try:\n",
    "    X_tune, X_val, y_tune, y_val = train_test_split(\n",
    "        X_train_selected, y_train, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 150),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 5, 15),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300),\n",
    "            \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 50),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        }\n",
    "        model = lgb.LGBMRegressor(\n",
    "            **params, random_state=42,\n",
    "            device='gpu', gpu_platform_id=0, gpu_device_id=0\n",
    "        )\n",
    "        model.fit(\n",
    "            X_tune, y_tune,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric='mae',\n",
    "            callbacks=[early_stopping(30), log_evaluation(0)]\n",
    "        )\n",
    "        return mean_absolute_error(y_val, model.predict(X_val))\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=30, timeout=1200)\n",
    "    best_params = study.best_params\n",
    "    print(\"‚úÖ Hyperparameter tuning completed. Best params:\", best_params)\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error during hyperparameter tuning:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# ======= Phase 12: Final Model Training =======\n",
    "print(\"üèÅ Phase 12: Training final LightGBM model...\")\n",
    "try:\n",
    "    final_model = lgb.LGBMRegressor(\n",
    "        **best_params, random_state=42,\n",
    "        device='gpu', gpu_platform_id=0, gpu_device_id=0\n",
    "    )\n",
    "    final_model.fit(X_train_selected, y_train)\n",
    "    print(\"‚úÖ Final model training completed.\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error during final model training:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# ======= Phase 13: Process Test Data =======\n",
    "print(\"üîÑ Phase 13: Processing test data...\")\n",
    "try:\n",
    "    # (a) Polynomial features\n",
    "    X_test_poly = pd.DataFrame(\n",
    "        poly.transform(X_test),\n",
    "        columns=poly.get_feature_names_out(X_test.columns),\n",
    "        index=X_test.index\n",
    "    )\n",
    "\n",
    "    # (b) Featuretools on test data\n",
    "    Xf_test = X_test.copy()\n",
    "    Xf_test['idx'] = Xf_test.index\n",
    "    es_test = ft.EntitySet(id=\"test_dataset\")\n",
    "    es_test.add_dataframe(dataframe_name=\"df\", dataframe=Xf_test, index=\"idx\")\n",
    "    fm_test = ft.calculate_feature_matrix(fdefs, entityset=es_test)\n",
    "    new_feats_test = [c for c in fm_test.columns if c not in X_test.columns and c != 'idx']\n",
    "    X_test_ft = fm_test[new_feats_test].reset_index(drop=True)\n",
    "\n",
    "    # (c) Combine\n",
    "    X_test_poly = X_test_poly.reset_index(drop=True)\n",
    "    X_test_final = pd.concat([X_test_poly, X_test_ft], axis=1)\n",
    "\n",
    "    # (d) Impute using TRAINING imputer\n",
    "    try:\n",
    "        imputer = joblib.load(imputer_path)  # Load imputer\n",
    "        if X_test_final.isnull().any().any():\n",
    "            X_test_final = pd.DataFrame(\n",
    "                imputer.transform(X_test_final),  # No fit here\n",
    "                columns=X_test_final.columns\n",
    "            )\n",
    "            print(\"‚úÖ Test missing values imputed using training imputer.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå Imputer not found. Skipping imputation for test data.\")\n",
    "\n",
    "    # (e) Scale\n",
    "    X_test_scaled = scaler.transform(X_test_final)\n",
    "\n",
    "    # (f) Select features\n",
    "    X_test_selected = selector.transform(X_test_scaled)\n",
    "    print(f\"‚úÖ Test data processed. Shape: {X_test_selected.shape}\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error processing test data:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# ======= Phase 14: Evaluate on Test Data =======\n",
    "print(\"üìä Phase 14: Evaluating model on test data...\")\n",
    "try:\n",
    "    y_pred = final_model.predict(X_test_selected)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2  = r2_score(y_test, y_pred)\n",
    "    print(f\"‚úÖ Test MAE: {mae:.4f}, R2: {r2:.4f}\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error during model evaluation:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# ======= Phase 15: Save Model =======\n",
    "print(\"üíæ Phase 15: Saving final model...\")\n",
    "try:\n",
    "    joblib.dump(final_model, model_path)\n",
    "    print(f\"‚úÖ Final model saved to {model_path}\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Error saving final model:\", e)\n",
    "\n",
    "print(f\"üéâ Pipeline completed in {time.time() - start_time:.2f} seconds.\")"
   ],
   "id": "c0065a23eaa928fe",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:27: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:28: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:29: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:31: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:33: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:39: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:27: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:28: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:29: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:30: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:31: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:33: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:39: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\Anuradha Kashaudhan\\AppData\\Local\\Temp\\ipykernel_3132\\467773482.py:27: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  model_path             = \"D:\\Python\\Models\\gpu_lightgbm_model.pkl\"\n",
      "C:\\Users\\Anuradha Kashaudhan\\AppData\\Local\\Temp\\ipykernel_3132\\467773482.py:28: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  scaler_path            = \"D:\\Python\\Models\\scaler.pkl\"\n",
      "C:\\Users\\Anuradha Kashaudhan\\AppData\\Local\\Temp\\ipykernel_3132\\467773482.py:29: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  selected_features_path = \"D:\\Python\\Models\\selected_features.pkl\"\n",
      "C:\\Users\\Anuradha Kashaudhan\\AppData\\Local\\Temp\\ipykernel_3132\\467773482.py:30: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  poly_path              = \"D:\\Python\\Models\\poly.pkl\"\n",
      "C:\\Users\\Anuradha Kashaudhan\\AppData\\Local\\Temp\\ipykernel_3132\\467773482.py:31: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  feature_defs_path      = \"D:\\Python\\Models\\Feature_defs.pkl\"\n",
      "C:\\Users\\Anuradha Kashaudhan\\AppData\\Local\\Temp\\ipykernel_3132\\467773482.py:32: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  X_columns_path         = \"D:\\Python\\Models\\X_columns.pkl\"\n",
      "C:\\Users\\Anuradha Kashaudhan\\AppData\\Local\\Temp\\ipykernel_3132\\467773482.py:33: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  imputer_path           = \"D:\\Python\\Models\\imputer.pkl\"  # Added imputer path\n",
      "C:\\Users\\Anuradha Kashaudhan\\AppData\\Local\\Temp\\ipykernel_3132\\467773482.py:39: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  data_path     = \"D:\\Python\\Datasets\\Handled_Training_Data.csv\"\n",
      "C:\\Users\\Anuradha Kashaudhan\\AppData\\Local\\Temp\\ipykernel_3132\\467773482.py:27: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  model_path             = \"D:\\Python\\Models\\gpu_lightgbm_model.pkl\"\n",
      "C:\\Users\\Anuradha Kashaudhan\\AppData\\Local\\Temp\\ipykernel_3132\\467773482.py:28: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  scaler_path            = \"D:\\Python\\Models\\scaler.pkl\"\n",
      "C:\\Users\\Anuradha Kashaudhan\\AppData\\Local\\Temp\\ipykernel_3132\\467773482.py:29: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  selected_features_path = \"D:\\Python\\Models\\selected_features.pkl\"\n",
      "C:\\Users\\Anuradha Kashaudhan\\AppData\\Local\\Temp\\ipykernel_3132\\467773482.py:30: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  poly_path              = \"D:\\Python\\Models\\poly.pkl\"\n",
      "C:\\Users\\Anuradha Kashaudhan\\AppData\\Local\\Temp\\ipykernel_3132\\467773482.py:31: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  feature_defs_path      = \"D:\\Python\\Models\\Feature_defs.pkl\"\n",
      "C:\\Users\\Anuradha Kashaudhan\\AppData\\Local\\Temp\\ipykernel_3132\\467773482.py:32: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  X_columns_path         = \"D:\\Python\\Models\\X_columns.pkl\"\n",
      "C:\\Users\\Anuradha Kashaudhan\\AppData\\Local\\Temp\\ipykernel_3132\\467773482.py:33: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  imputer_path           = \"D:\\Python\\Models\\imputer.pkl\"  # Added imputer path\n",
      "C:\\Users\\Anuradha Kashaudhan\\AppData\\Local\\Temp\\ipykernel_3132\\467773482.py:39: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  data_path     = \"D:\\Python\\Datasets\\Handled_Training_Data.csv\"\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m     12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mensemble\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m IsolationForest\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfeature_selection\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SelectFromModel\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlightgbm\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlgb\u001B[39;00m\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlightgbm\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m early_stopping, log_evaluation\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mcatboost\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mcb\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'lightgbm'"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
