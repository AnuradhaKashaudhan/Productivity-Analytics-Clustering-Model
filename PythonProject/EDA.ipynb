{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# %%\n",
    "# ===============================================================\n",
    "# Final Advanced Enhanced EDA Code for Employee Productivity Analysis\n",
    "# ===============================================================\n",
    "\n",
    "# Enable inline plotting for Matplotlib\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "# Set Plotly renderer for notebooks\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = 'notebook_connected'\n",
    "\n",
    "# Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "# Import AutoViz for enhanced profiling\n",
    "from autoviz.AutoViz_Class import AutoViz_Class\n",
    "\n",
    "# Set global visualization parameters\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1. Data Loading\n",
    "# ---------------------------------------------------------------\n",
    "data_path = r\"D:\\Python\\Machine Learning\\Datasets\\Extended_Employee_Performance_and_Productivity_Data.csv\"\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(\"Data loaded successfully from:\", data_path)\n",
    "else:\n",
    "    print(f\"File not found: {data_path}\")\n",
    "    raise SystemExit(\"Stopping execution due to missing dataset.\")\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Dataset columns:\", df.columns.tolist())\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2. Basic Inspection & Enhanced Data Quality Analysis\n",
    "# ---------------------------------------------------------------\n",
    "print(\"\\n--- DataFrame Head ---\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n--- DataFrame Info ---\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n--- Summary Statistics ---\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n--- Missing Values Count ---\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3. AutoViz for Advanced Data Profiling\n",
    "# ---------------------------------------------------------------\n",
    "print(\"\\n--- AutoViz Report Generation ---\")\n",
    "AV = AutoViz_Class()\n",
    "autoviz_report = AV.AutoViz(data_path, depVar=\"\", verbose=1, chart_format=\"svg\", save_plot_dir=None)\n",
    "print(\"AutoViz report generated successfully.\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4. Synthetic Data Generation Without SDV\n",
    "# ---------------------------------------------------------------\n",
    "print(\"\\n--- Synthetic Data Generation Without SDV ---\")\n",
    "\n",
    "\n",
    "def generate_synthetic_data(df, sample_size=100):\n",
    "    \"\"\"\n",
    "    Generate synthetic data based on statistical properties of the original dataset.\n",
    "    Args:\n",
    "    - df (DataFrame): The original DataFrame.\n",
    "    - sample_size (int): Number of synthetic rows to generate.\n",
    "\n",
    "    Returns:\n",
    "    Synthetic DataFrame resembling the original dataset.\n",
    "    \"\"\"\n",
    "    synthetic_data = pd.DataFrame()\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype in [np.float64, np.int64]:  # Numeric columns\n",
    "            mean, std = df[column].mean(), df[column].std()\n",
    "            synthetic_data[column] = np.random.normal(loc=mean, scale=std, size=sample_size)\n",
    "        elif df[column].dtype == 'object':  # Categorical columns\n",
    "            synthetic_data[column] = np.random.choice(df[column].dropna().unique(), size=sample_size)\n",
    "        else:  # Handle other data types if required\n",
    "            synthetic_data[column] = np.nan\n",
    "    return synthetic_data\n",
    "\n",
    "\n",
    "# Generate synthetic data based on the original dataset\n",
    "synthetic_df = generate_synthetic_data(df, sample_size=100)\n",
    "\n",
    "print(\"Synthetic Data Sample:\")\n",
    "print(synthetic_df.head())\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5. Data Cleaning\n",
    "# ---------------------------------------------------------------\n",
    "print(\"\\n--- Data Cleaning ---\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"After removing duplicates, shape:\", df.shape)\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        median_val = df[col].median()\n",
    "        df[col].fillna(median_val, inplace=True)\n",
    "        print(f\"Filled missing values in {col} with median: {median_val}\")\n",
    "\n",
    "\n",
    "# Remove outliers using IQR method\n",
    "def remove_outliers_iqr(dataframe, column):\n",
    "    Q1 = dataframe[column].quantile(0.25)\n",
    "    Q3 = dataframe[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    before = dataframe.shape[0]\n",
    "    dataframe = dataframe[(dataframe[column] >= lower_bound) & (dataframe[column] <= upper_bound)]\n",
    "    after = dataframe.shape[0]\n",
    "    print(f\"Removed outliers in {column}: {before - after} rows removed.\")\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "for col in ['Work_Hours_Per_Week', 'Monthly_Salary']:\n",
    "    if col in df.columns:\n",
    "        df = remove_outliers_iqr(df, col)\n",
    "    else:\n",
    "        print(f\"Column '{col}' not found; skipping\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b9574f7a895b909a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-08T09:22:38.959667Z",
     "start_time": "2025-04-08T09:22:38.824711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pkg_resources\n",
    "try:\n",
    "    pkg_resources.get_distribution('xgboost')\n",
    "    print(\"xgboost is installed\")\n",
    "except:\n",
    "    print(\"xgboost is NOT installed\")"
   ],
   "id": "5a9b3b5544b3c951",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost is installed\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "204800ff6fb9be50"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
